1
00:00:00,000 --> 00:00:04,342
<lang xml:lang="ko-KR"> 이번에는 cross attention 부분을 어떻게 구현하는가를

2
00:00:04,442 --> 00:00:08,108
살펴보겠습니다. 앞에서 만들었던 base attetion을 이용할 것입니다. </lang>

3
00:00:10,200 --> 00:00:11,660
<lang xml:lang="ko-KR"> 시작해보겠습니다. </lang>

4
00:00:12,733 --> 00:00:15,441
<lang xml:lang="ko-KR"> 이 클래스의 이름은 cross attention입니다. </lang>

5
00:00:16,533 --> 00:00:22,163
<lang xml:lang="ko-KR"> 이 클래스는 앞에서 만들었던 base attention을 상속받습니다. 따라서 굳이

6
00:00:22,263 --> 00:00:25,601
m h a, add 등을 설정하지 않아도 사용할 수 있습니다. </lang>

7
00:00:25,666 --> 00:00:28,907
<lang xml:lang="ko-KR"> 이제 base attention class가 만들어질

8
00:00:29,007 --> 00:00:30,798
때 초기화해야 하는 일을 정의하겠습니다. </lang>

9
00:00:30,866 --> 00:00:36,349
<lang xml:lang="ko-KR"> super는 나의 상위 클래스를 의미합니다. 즉, default라고 설명했던

10
00:00:36,449 --> 00:00:41,086
keras layer를 초기화하는 것입니다. 이것도 default라고 생각하면 됩니다. </lang>

11
00:00:41,133 --> 00:00:46,748
<lang xml:lang="ko-KR"> 이제 세개의 변수를 정의하겠습니다. 이 세가지 변수만 정의하면 base

12
00:00:46,848 --> 00:00:51,737
attention은 끝입니다. 일단, 이름을 보고 무엇을 만들지 짐작해보기 바랍니다. </lang>

13
00:00:54,800 --> 00:00:58,561
<lang xml:lang="ko-KR"> Multi head attention이라는 layer를 부르고,

14
00:00:58,661 --> 00:01:00,460
그것을 m h a라는 변수에 넣습니다. </lang>

15
00:01:00,533 --> 00:01:07,038
<lang xml:lang="ko-KR"> 다음으로는 layer normalization이라는 layer를 부르고 그것을 layernorm에

16
00:01:07,138 --> 00:01:10,849
넣습니다. 이 layer의 구체적인 역할에 대해서는 다시 설명하겠지만, 기본적으로

17
00:01:10,949 --> 00:01:13,729
모형이 더 빠르게 수렴하게 하는 역할을 합니다. </lang>

18
00:01:13,800 --> 00:01:20,288
<lang xml:lang="ko-KR"> 마지막 layer는 더하기 layer입니다. Transformer 아키텍쳐를 기억해 보면, Add and

19
00:01:20,388 --> 00:01:24,788
Norm 이라는 부분이 있었습니다. 그 부분을 구현하기 위해서 필요한 layer입니다. </lang>

20
00:01:24,866 --> 00:01:29,097
<lang xml:lang="ko-KR"> 지금까지 만든 모든 layer는 다 keras layer입니다.

21
00:01:29,197 --> 00:01:32,326
따라서 앞에 tf keras layers 라고 붙여주어야 합니다. </lang>

22
00:01:33,400 --> 00:01:39,512
<lang xml:lang="ko-KR"> 마지막으로 이 부분. keyword arguments 부분이 굉장히 신경쓰일텐데, 이것은

23
00:01:39,612 --> 00:01:43,428
나중에 이 클래스를 부를 때 보내주는 인자를 받아오기 위한 것입니다. </lang>

24
00:01:44,466 --> 00:01:49,094
<lang xml:lang="ko-KR"> 예를 들어, 이렇게 인자들을 보내면, 이것을 여기에서 받아옵니다. </lang>

25
00:01:50,200 --> 00:01:53,546
<lang xml:lang="ko-KR"> 이상의 base attention class를 기반으로

26
00:01:53,646 --> 00:01:56,100
세가지의 서로 다른 attention을 구현해 보겠습니다. </lang>

